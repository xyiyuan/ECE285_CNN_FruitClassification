{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import lib\n",
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import math\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training set...\n",
      "Done\n",
      "Loading test set...\n",
      "Done\n",
      "Splitting into val/test set...\n",
      "Done\n",
      "Normalization...\n",
      "Done\n",
      "Converting to one-hot code...\n",
      "Done\n",
      "Generating Gaussian noise images...\n",
      "Done\n",
      "Stacking Gaussian noise images...\n",
      "Done\n",
      "Generating perspective images...\n",
      "Done\n",
      "Stacking perspective images...\n",
      "Done\n",
      "Finished!\n",
      "number of training examples = 86208\n",
      "number of test examples = 4832\n",
      "X_train shape: (86208, 100, 100, 3)\n",
      "Y_train shape: (86208, 60)\n",
      "X_val shape: (4839, 100, 100, 3)\n",
      "Y_val shape: (4839, 60)\n",
      "X_test shape: (4832, 100, 100, 3)\n",
      "Y_test shape: (4832, 60)\n"
     ]
    }
   ],
   "source": [
    "# data processing\n",
    "%run 'Data Augmentation.ipynb'\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "#print (\"number of validation examples = \" + str(X_val.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_val shape: \" + str(X_val.shape))\n",
    "print (\"Y_val shape: \" + str(Y_val.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n",
    "def build_model():\n",
    "    base_model = keras.applications.VGG16(input_shape=(100,100,3), include_top=False, weights='imagenet')\n",
    "    base_model_output = base_model.output\n",
    "    x = keras.layers.Flatten(name='flatten')(base_model_output)\n",
    "    #x = keras.layers.Dense(1024, activation='relu', name='fc1')(x)\n",
    "    #x = keras.layers.Dropout(0.25, name='dropout1')(x)\n",
    "    #x = keras.layers.Dense(256, activation='relu', name='fc2')(x)\n",
    "    #x = keras.layers.Dropout(0.5, name='dropout2')(x)\n",
    "    out = keras.layers.Dense(60, name='output', activation='softmax')(x)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = keras.models.Model(inputs=base_model.input, outputs=out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 60)                276540    \n",
      "=================================================================\n",
      "Total params: 14,991,228\n",
      "Trainable params: 276,540\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy'], \n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=0.001,beta1=0.9,beta2=0.999,epsilon=1e-08,use_locking=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86208 samples, validate on 4839 samples\n",
      "Epoch 1/32\n",
      "86208/86208 [==============================] - 75s - loss: 1.2640 - acc: 0.7911 - val_loss: 0.4503 - val_acc: 0.9206\n",
      "Epoch 2/32\n",
      "86208/86208 [==============================] - 74s - loss: 0.3328 - acc: 0.9650 - val_loss: 0.2698 - val_acc: 0.9475\n",
      "Epoch 3/32\n",
      "86208/86208 [==============================] - 72s - loss: 0.1868 - acc: 0.9828 - val_loss: 0.2160 - val_acc: 0.9531\n",
      "Epoch 4/32\n",
      "86208/86208 [==============================] - 72s - loss: 0.1251 - acc: 0.9901 - val_loss: 0.1710 - val_acc: 0.9624\n",
      "Epoch 5/32\n",
      "86208/86208 [==============================] - 72s - loss: 0.0918 - acc: 0.9934 - val_loss: 0.1575 - val_acc: 0.9628\n",
      "Epoch 6/32\n",
      "86208/86208 [==============================] - 72s - loss: 0.0706 - acc: 0.9958 - val_loss: 0.1412 - val_acc: 0.9642\n",
      "Epoch 7/32\n",
      "86208/86208 [==============================] - 72s - loss: 0.0562 - acc: 0.9969 - val_loss: 0.1359 - val_acc: 0.9645\n",
      "Epoch 8/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0459 - acc: 0.9978 - val_loss: 0.1271 - val_acc: 0.9669\n",
      "Epoch 9/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0383 - acc: 0.9984 - val_loss: 0.1231 - val_acc: 0.9673\n",
      "Epoch 10/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0325 - acc: 0.9988 - val_loss: 0.1128 - val_acc: 0.9686\n",
      "Epoch 11/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0280 - acc: 0.9991 - val_loss: 0.1065 - val_acc: 0.9684\n",
      "Epoch 12/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0243 - acc: 0.9992 - val_loss: 0.1107 - val_acc: 0.9702\n",
      "Epoch 13/32\n",
      "86208/86208 [==============================] - 72s - loss: 0.0212 - acc: 0.9995 - val_loss: 0.1113 - val_acc: 0.9671\n",
      "Epoch 14/32\n",
      "86208/86208 [==============================] - 72s - loss: 0.0188 - acc: 0.9996 - val_loss: 0.1029 - val_acc: 0.9700\n",
      "Epoch 15/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0165 - acc: 0.9998 - val_loss: 0.1015 - val_acc: 0.9698\n",
      "Epoch 16/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0147 - acc: 0.9998 - val_loss: 0.1048 - val_acc: 0.9702\n",
      "Epoch 17/32\n",
      "86208/86208 [==============================] - 72s - loss: 0.0131 - acc: 0.9999 - val_loss: 0.0917 - val_acc: 0.9719\n",
      "Epoch 18/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0119 - acc: 0.9998 - val_loss: 0.0929 - val_acc: 0.9713\n",
      "Epoch 19/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0106 - acc: 0.9999 - val_loss: 0.0983 - val_acc: 0.9717\n",
      "Epoch 20/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0096 - acc: 0.9999 - val_loss: 0.0896 - val_acc: 0.9707\n",
      "Epoch 21/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0087 - acc: 0.9999 - val_loss: 0.0903 - val_acc: 0.9704\n",
      "Epoch 22/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0959 - val_acc: 0.9711\n",
      "Epoch 23/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0900 - val_acc: 0.9700\n",
      "Epoch 24/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0955 - val_acc: 0.9713\n",
      "Epoch 25/32\n",
      "86208/86208 [==============================] - 70s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0903 - val_acc: 0.9715\n",
      "Epoch 26/32\n",
      "86208/86208 [==============================] - 70s - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 0.9715\n",
      "Epoch 27/32\n",
      "86208/86208 [==============================] - 71s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0885 - val_acc: 0.9727\n",
      "Epoch 28/32\n",
      " 1536/86208 [..............................] - ETA: 63s - loss: 0.0046 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train, \n",
    "    batch_size = 512, \n",
    "    epochs = 32, \n",
    "    verbose = 1, \n",
    "    shuffle = True,\n",
    "    validation_data=(X_val, Y_val))\n",
    "\n",
    "end=time.time()\n",
    "runtime=end-start\n",
    "print(\"Runtime: \"+str(runtime)+\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "\n",
    "scores = model.evaluate(\n",
    "    test_images,\n",
    "    test_labels, \n",
    "    batch_size = 32, \n",
    "    verbose = 1, \n",
    "    sample_weight=None, \n",
    "    steps=None)\n",
    "\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "end=time.time()\n",
    "runtime=end-start\n",
    "print(\"Runtime: \"+str(runtime)+\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
