{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import lib\n",
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import math\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'Data Preprocessing.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run 'DA-Gaussian.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run 'DA-salt&pepper.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run 'DA-perspective.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of validation examples = \" + str(X_val.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_val shape: \" + str(X_val.shape))\n",
    "print (\"Y_val shape: \" + str(Y_val.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"Placeholder:0\", shape=(?, 100, 100, 3), dtype=float32)\n",
      "y = Tensor(\"Placeholder_1:0\", shape=(?, 60), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# create placeholder for x and y\n",
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_H0, n_W0, n_C0])\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, n_y])\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "x, y = create_placeholders(100, 100, 3, 60)\n",
    "print (\"x = \" + str(x))\n",
    "print (\"y = \" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \n",
    "    tf.set_random_seed(1)\n",
    "    \n",
    "    w1_shape = [3,3,3,16]\n",
    "    w2_shape = [3,3,16,32]\n",
    "    w3_shape = [3,3,32,32]\n",
    "    w4_shape = [3,3,32,64]\n",
    "    \n",
    "    w1 = tf.get_variable('w1', w1_shape, initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    w2 = tf.get_variable('w2', w2_shape, initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    w3 = tf.get_variable('w3', w3_shape, initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    w4 = tf.get_variable('w4', w4_shape, initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    \n",
    "    parameters = {'w1': w1, 'w2': w2, 'w3': w3, 'w4': w4}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward_propagation\n",
    "\n",
    "def forward_propagation(x, parameters, prob):\n",
    "    # retrieve weights\n",
    "    w1 = parameters['w1']\n",
    "    w2 = parameters['w2']\n",
    "    w3 = parameters['w3']\n",
    "    w4 = parameters['w4']\n",
    "    \n",
    "    # conv1: k = (3,3), input = (100,100,3), output = 16, padding=0, stride =1\n",
    "    x = tf.nn.conv2d(x, w1, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "    # batchnormalization\n",
    "    x = tf.layers.batch_normalization(x)\n",
    "    # relu\n",
    "    x = tf.nn.leaky_relu(x, alpha=0.5)\n",
    "    # maxpool: (2,2), stride = 2, padding = 0\n",
    "    x = tf.nn.max_pool(x, ksize=[1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "\n",
    "    \n",
    "    # conv2: k = (3,3), input = 16, output = 32\n",
    "    x = tf.nn.conv2d(x, w2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # batchnormalization\n",
    "    x = tf.layers.batch_normalization(x)\n",
    "    # relu\n",
    "    x = tf.nn.leaky_relu(x, alpha=0.5)\n",
    "    # maxpool: (2,2)\n",
    "    x = tf.nn.max_pool(x, ksize=[1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "    \n",
    "    # conv3\n",
    "    x = tf.nn.conv2d(x, w3, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # batchnormalization\n",
    "    x = tf.layers.batch_normalization(x)\n",
    "    # relu\n",
    "    x = tf.nn.leaky_relu(x, alpha=0.5)\n",
    "    # maxpool: (2,2)\n",
    "    x = tf.nn.max_pool(x, ksize=[1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "    \n",
    "    # conv4\n",
    "    x = tf.nn.conv2d(x, w4, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # batchnormalization\n",
    "    x = tf.layers.batch_normalization(x)\n",
    "    # relu\n",
    "    x = tf.nn.leaky_relu(x, alpha=0.5)\n",
    "    # maxpool: (2,2)\n",
    "    x = tf.nn.max_pool(x, ksize=[1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n",
    "          \n",
    "    # flatten\n",
    "    x = tf.contrib.layers.flatten(x)\n",
    "    \n",
    "    # fully-connected \n",
    "    # dense1\n",
    "    x = tf.contrib.layers.fully_connected(x, 256, activation_fn = tf.nn.relu)\n",
    "    # dropout\n",
    "    x = tf.nn.dropout(x, keep_prob=prob)\n",
    "    \n",
    "    # dense2\n",
    "    y = tf.contrib.layers.fully_connected(x, 60, activation_fn = None)\n",
    "    \n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cost\n",
    "def compute_cost(y_pred, y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_pred, labels = y)) \n",
    "    return cost\n",
    "\n",
    "def compute_accuracy(y_pred, x, y, size, x_, y_, prob, dropout):\n",
    "    correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y_pred),1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    num = int(x_.shape[0]/size)\n",
    "    acc_ = 0\n",
    "    for i in range(num):\n",
    "        acc = accuracy.eval({x:x_[i*size:(i+1)*size], y:y_[i*size:(i+1)*size], prob:dropout})\n",
    "        acc_ += acc/num\n",
    "\n",
    "    return acc_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def training(xtrain, ytrain, xtest, ytest, alpha = 0.001, epochs = 10, minibatch_size = 128, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()\n",
    "    tf.set_random_seed(1)\n",
    "    (m, n_H0, n_W0, n_C0) = xtrain.shape\n",
    "    n_y = ytrain.shape[1]\n",
    "    costs = []\n",
    "    costs_test = []\n",
    "    accs_train = []\n",
    "    accs_test = []\n",
    "    minibatch_num = int(m/minibatch_size)\n",
    "    \n",
    "    x,y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    prob = tf.placeholder_with_default(1.0, shape=())\n",
    "    \n",
    "    # initialize\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # forwardprop\n",
    "    y_pred = forward_propagation(x, parameters, prob)\n",
    "    \n",
    "    # cost function\n",
    "    cost = compute_cost(y_pred, y)\n",
    "    \n",
    "    # backprop\n",
    "    optimizer = tf.train.AdamOptimizer(alpha).minimize(cost)\n",
    "       \n",
    "    # initialize\n",
    "    init = tf.global_variables_initializer()\n",
    "    init2 = tf.local_variables_initializer()\n",
    "    \n",
    "     \n",
    "    \n",
    "    # session\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        sess.run(init2)\n",
    "                    \n",
    "        # training\n",
    "        for epo in range(epochs):\n",
    "            tf.set_random_seed(1)\n",
    "            minibatch_cost = 0\n",
    "            cost_test = 0\n",
    "            \n",
    "            # shuffle\n",
    "            minibatch = np.random.choice(np.random.permutation(m), \n",
    "                                         minibatch_size * minibatch_num).reshape(minibatch_num, minibatch_size)\n",
    "            minibatch_index = np.random.permutation(minibatch_num)  \n",
    "                       \n",
    "            for mb in range(minibatch_num):\n",
    "                i = minibatch_index[mb]\n",
    "                indx = minibatch[i]\n",
    "                inputs = xtrain[indx]\n",
    "                labels = ytrain[indx]\n",
    "\n",
    "                # feed the inputs\n",
    "                _, temp_cost = sess.run([optimizer, cost], feed_dict={x: inputs, y: labels, prob:0.5})\n",
    "                \n",
    "                # calculate average cost after 1 epoch\n",
    "                minibatch_cost += temp_cost / minibatch_num\n",
    "            \n",
    "            \n",
    "            # calculate cost of test set after 1 epoch\n",
    "            for i in range(5):\n",
    "                temp_test = sess.run(cost, feed_dict={x:xtest[i*967:(i+1)*967], y:ytest[i*967:(i+1)*967], prob:1})\n",
    "                cost_test += temp_test / 5\n",
    "\n",
    "            \n",
    "            # add cost of this epoch to the lists\n",
    "            costs.append(minibatch_cost)\n",
    "            costs_test.append(cost_test)\n",
    "            \n",
    "            acc_train = compute_accuracy(y_pred, x, y, 967, xtrain, ytrain, prob, dropout=0.5) \n",
    "            accs_train.append(acc_train)\n",
    "            acc_test = compute_accuracy(y_pred, x, y, 967, xtest, ytest, prob, dropout=1) \n",
    "            accs_test.append(acc_test)\n",
    "            \n",
    "            # print result\n",
    "            if print_cost == True and epo % 5 == 4:\n",
    "                print('Cost after epoch %i: %f' %(epo+1, minibatch_cost))\n",
    "                print('Validation cost after epoch %i: %f' %(epo+1, cost_test))\n",
    "                \n",
    "                print('Training accuracy after epoch %i: %f' %(epo+1, acc_train))\n",
    "\n",
    "                print('Validation accuracy after epoch %i: %f' %(epo+1, acc_test))\n",
    "        \n",
    "                    \n",
    "        # plot cost\n",
    "        plt.plot(np.squeeze(range(1,epochs+1)),np.squeeze(costs), label = 'train')\n",
    "        plt.plot(np.squeeze(range(1,epochs+1)),np.squeeze(costs_test), label = 'validation')\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.xticks(range(1,epochs+1))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        # plot accuracy\n",
    "        plt.plot(np.squeeze(range(1,epochs+1)),np.squeeze(accs_train), label = 'train')\n",
    "        plt.plot(np.squeeze(range(1,epochs+1)),np.squeeze(accs_test), label = 'validation')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.xticks(range(1,epochs+1))\n",
    "        plt.legend()\n",
    "        plt.show()       \n",
    "        \n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = training(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
